{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_stop=15\n",
    "df = pd.read_csv(\"cfs_formatted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYP 1\n",
    "\n",
    "# num = 41\n",
    "# Identify separator rows and create a group for each original data section\n",
    "df = pd.read_csv(\"cfs_formatted.csv\")\n",
    "separator_mask = df.apply(lambda row: all(cell == \"---\" for cell in row), axis=1)\n",
    "df['group_id'] = separator_mask.cumsum()\n",
    "\n",
    "# List to collect paired results\n",
    "all_paired_rows = []\n",
    "\n",
    "# Iterate over groups to find pairs within each\n",
    "for group_id, group_df in df.groupby('group_id'):\n",
    "    # Filter out separator rows within each group\n",
    "    group_df = group_df[~separator_mask]\n",
    "\n",
    "    # Identify rows excluding the original row for pairing\n",
    "    proximity_rows = group_df[group_df['source'].str.startswith('prox')]\n",
    "\n",
    "    # Check if there are at least two rows for pairing\n",
    "    if len(proximity_rows) > 1:\n",
    "        # Treat the first row as the 'original_data' row for context\n",
    "        original_data_row = group_df[group_df['source'] == 'original'].iloc[0]\n",
    "\n",
    "        # Temporary list to collect pairs for this group\n",
    "        group_paired_rows = []\n",
    "\n",
    "        # Iterate over all possible pairs of proximity rows\n",
    "        for i in range(len(proximity_rows)):\n",
    "            for j in range(len(proximity_rows)):\n",
    "                if i != j:  # Ensure we are comparing different rows\n",
    "                    row_i = proximity_rows.iloc[i]\n",
    "                    row_j = proximity_rows.iloc[j]\n",
    "                    if (\n",
    "                        original_data_row['income'] <= row_i['income'] and \n",
    "                        original_data_row['income'] <= row_j['income'] and \n",
    "                        original_data_row['credit_score'] <= row_i['credit_score'] and \n",
    "                        original_data_row['credit_score'] <= row_j['credit_score'] and \n",
    "                        original_data_row['amount_requested'] >= row_i['amount_requested'] and \n",
    "                        original_data_row['amount_requested'] >= row_j['amount_requested']\n",
    "                    ):\n",
    "                        if original_data_row['employment_type'] == 'private':\n",
    "                            condition = (row_i['employment_type'] in ('private', 'govt')) and (row_j['employment_type'] in ('private', 'govt'))\n",
    "                        elif original_data_row['employment_type'] == 'govt':\n",
    "                            condition = (row_i['employment_type'] == 'govt') and (row_j['employment_type'] == 'govt')\n",
    "                        elif original_data_row['employment_type'] == 'self':\n",
    "                            condition = (row_i['employment_type'] in ('self', 'private', 'govt')) and (row_j['employment_type'] in ('self', 'private', 'govt'))\n",
    "                        else:\n",
    "                            condition = False  # or handle other cases\n",
    "\n",
    "                        if condition:\n",
    "                            if original_data_row['education_type'] == 'less_than_high_school':\n",
    "                                condition2 = (row_i['education_type'] in (\"less_than_high_school\", \"highschool\", \"associate\", \"bachelors\", \"advanced\")) and (row_j['education_type'] in (\"less_than_high_school\", \"highschool\", \"associate\", \"bachelors\", \"advanced\"))\n",
    "                            elif original_data_row['education_type'] == 'highschool':\n",
    "                                condition2 = (row_i['education_type'] in (\"highschool\", \"associate\", \"bachelors\", \"advanced\")) and (row_j['education_type'] in (\"highschool\", \"associate\", \"bachelors\", \"advanced\"))\n",
    "                            elif original_data_row['education_type'] == 'associate':\n",
    "                                condition2 = (row_i['education_type'] in (\"associate\", \"bachelors\", \"advanced\")) and (row_j['education_type'] in (\"associate\", \"bachelors\", \"advanced\"))\n",
    "                            elif original_data_row['education_type'] == 'bachelors':\n",
    "                                condition2 = (row_i['education_type'] in (\"bachelors\", \"advanced\")) and (row_j['education_type'] in (\"bachelors\", \"advanced\"))\n",
    "                            elif original_data_row['education_type'] == 'advanced':\n",
    "                                condition2 = (row_i['education_type'] == \"advanced\") and (row_j['education_type'] == \"advanced\")\n",
    "                            else:\n",
    "                                condition2 = False\n",
    "                            if condition2:\n",
    "                                # Ensure numeric conversion with error handling\n",
    "                                row_i['true_proximity'] = float(row_i['true_proximity'])\n",
    "                                row_j['true_proximity'] = float(row_j['true_proximity'])\n",
    "                                row_i['weighted_proximity'] = float(row_i['weighted_proximity'])\n",
    "                                row_j['weighted_proximity'] = float(row_j['weighted_proximity'])\n",
    "\n",
    "                                # Check if the pair meets the mismatch condition\n",
    "                                if (\n",
    "                                    row_i['true_proximity'] > row_j['true_proximity'] and\n",
    "                                    row_i['weighted_proximity'] < row_j['weighted_proximity']\n",
    "                                ):\n",
    "                                    # Blank out unchanged features for row_i\n",
    "                                    greater_row = row_i.copy()\n",
    "                                    for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                                        if greater_row[column] == original_data_row[column]:\n",
    "                                            greater_row[column] = \"\"  # Blank out if unchanged\n",
    "\n",
    "                                    # Blank out unchanged features for row_j\n",
    "                                    lesser_row = row_j.copy()\n",
    "                                    for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                                        if lesser_row[column] == original_data_row[column]:\n",
    "                                            lesser_row[column] = \"\"  # Blank out if unchanged\n",
    "\n",
    "                                    group_paired_rows.append(greater_row.to_dict())\n",
    "                                    group_paired_rows.append(lesser_row.to_dict())\n",
    "                                    # Append a separator row for readability\n",
    "                                    separator = {col: \"---\" for col in df.columns}\n",
    "                                    group_paired_rows.append(separator)\n",
    "        \n",
    "        # Only append the original row if there are pairs in this group\n",
    "        if group_paired_rows:\n",
    "            all_paired_rows.append(original_data_row.to_dict())\n",
    "            all_paired_rows.extend(group_paired_rows)\n",
    "\n",
    "# Output debug information if no pairs were found\n",
    "if not all_paired_rows:\n",
    "    print(\"No pairs found. Review the mismatch condition or the data structure.\")\n",
    "    \n",
    " \n",
    "output_df = pd.DataFrame(all_paired_rows)\n",
    "output_df.to_csv(\"hyp1_cfs.csv\", index=False)   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYP 2\n",
    "\n",
    "round_df = pd.read_csv(\"round_cfs_formatted.csv\")\n",
    "\n",
    "# Identify separator rows and create a group for each original data section\n",
    "separator_mask = round_df.apply(lambda row: all(cell == \"---\" for cell in row), axis=1)\n",
    "round_df['group_id'] = separator_mask.cumsum()\n",
    "\n",
    "# List to collect valid paired groups\n",
    "all_paired_rows = []\n",
    "\n",
    "# Iterate over groups to filter and format data as specified\n",
    "for group_id, group_df in round_df.groupby('group_id'):\n",
    "    # Filter out separator rows within each group\n",
    "    group_df = group_df[~separator_mask]\n",
    "\n",
    "    # Check if there's an original row in the group\n",
    "    original_data_row = group_df[group_df['source'] == \"original\"]\n",
    "    if original_data_row.empty:\n",
    "        continue\n",
    "    original_data_row = original_data_row.iloc[0]\n",
    "\n",
    "    # Collect prox and round_prox pairs for the current group\n",
    "    valid_prox_rows = []\n",
    "    for prox_num in range(1, leaf_stop):\n",
    "        prox_row = group_df[group_df['source'] == f\"prox{prox_num}\"]\n",
    "        round_prox_row = group_df[group_df['source'] == f\"round_prox{prox_num}\"]\n",
    "\n",
    "        # Include only complete prox and round_prox pairs\n",
    "        if not prox_row.empty and not round_prox_row.empty:\n",
    "            prox_row = prox_row.iloc[0]\n",
    "            round_prox_row = round_prox_row.iloc[0]\n",
    "\n",
    "            if (\n",
    "                original_data_row['income'] <= prox_row['income'] and \n",
    "                original_data_row['credit_score'] <= prox_row['credit_score'] and \n",
    "                original_data_row['amount_requested'] >= prox_row['amount_requested']\n",
    "            ):\n",
    "                if original_data_row['employment_type'] == 'private':\n",
    "                    condition = (prox_row['employment_type'] in ('private', 'govt'))\n",
    "                elif original_data_row['employment_type'] == 'govt':\n",
    "                    condition = (prox_row['employment_type'] == 'govt')\n",
    "                elif original_data_row['employment_type'] == 'self':\n",
    "                    condition = (prox_row['employment_type'] in ('self', 'private', 'govt'))\n",
    "                else:\n",
    "                    condition = False  # or handle other cases\n",
    "                    \n",
    "                if condition:\n",
    "                    if original_data_row['education_type'] == 'less_than_high_school':\n",
    "                        condition2 = (prox_row['education_type'] in (\"less_than_high_school\", \"highschool\", \"associate\", \"bachelors\", \"advanced\"))\n",
    "                    elif original_data_row['education_type'] == 'highschool':\n",
    "                        condition2 = (prox_row['education_type'] in (\"highschool\", \"associate\", \"bachelors\", \"advanced\"))\n",
    "                    elif original_data_row['education_type'] == 'associate':\n",
    "                        condition2 = (prox_row['education_type'] in (\"associate\", \"bachelors\", \"advanced\"))\n",
    "                    elif original_data_row['education_type'] == 'bachelors':\n",
    "                        condition2 = (prox_row['education_type'] in (\"bachelors\", \"advanced\"))\n",
    "                    elif original_data_row['education_type'] == 'advanced':\n",
    "                        condition2 = (prox_row['education_type'] == \"advanced\")\n",
    "                    else:\n",
    "                        condition2 = False\n",
    "                        \n",
    "                    if condition2:\n",
    "                        # Blank unchanged features for prox_row\n",
    "                        prox_row_modified = prox_row.copy()\n",
    "                        for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                            if prox_row_modified[column] == original_data_row[column]:\n",
    "                                prox_row_modified[column] = \"\"  # Blank out if unchanged\n",
    "                        valid_prox_rows.append(prox_row_modified.to_dict())\n",
    "\n",
    "                        # Blank unchanged features for round_prox_row\n",
    "                        round_prox_row_modified = round_prox_row.copy()\n",
    "                        for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                            if round_prox_row_modified[column] == original_data_row[column]:\n",
    "                                round_prox_row_modified[column] = \"\"  # Blank out if unchanged\n",
    "                        valid_prox_rows.append(round_prox_row_modified.to_dict())\n",
    "\n",
    "    if valid_prox_rows:\n",
    "        all_paired_rows.append(original_data_row.to_dict())\n",
    "        all_paired_rows.extend(valid_prox_rows)\n",
    "\n",
    "        # Append a separator row after each original group for readability\n",
    "        separator = {col: \"---\" for col in df.columns}\n",
    "        all_paired_rows.append(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the paired rows to a DataFrame and output to CSV\n",
    "output_df = pd.DataFrame(all_paired_rows)\n",
    "output_df.to_csv(\"hyp2_cfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYP 3\n",
    "\n",
    "df = pd.read_csv(\"cfs_formatted.csv\")\n",
    "\n",
    "# Identify separator rows and create a group for each original data section\n",
    "separator_mask = df.apply(lambda row: all(cell == \"---\" for cell in row), axis=1)\n",
    "df['group_id'] = separator_mask.cumsum()\n",
    "\n",
    "# List to collect paired results\n",
    "all_paired_rows = []\n",
    "\n",
    "# Iterate over groups to find pairs within each\n",
    "for group_id, group_df in df.groupby('group_id'):\n",
    "    # Filter out separator rows within each group\n",
    "    group_df = group_df[~separator_mask]\n",
    "\n",
    "    # Identify rows excluding the original row for pairing\n",
    "    proximity_rows = group_df[group_df['source'].str.startswith('prox')]\n",
    "\n",
    "    # Check if there are at least two rows for pairing\n",
    "    if len(proximity_rows) > 1:\n",
    "        # Treat the first row as the 'original_data' row for context\n",
    "        original_data_row = group_df[group_df['source'] == 'original'].iloc[0]\n",
    "\n",
    "        # Temporary list to collect pairs for this group\n",
    "        group_paired_rows = []\n",
    "\n",
    "        # Iterate over all possible pairs of proximity rows\n",
    "        for i in range(len(proximity_rows)):\n",
    "            for j in range(len(proximity_rows)):\n",
    "                if i != j:  # Ensure we are comparing different rows\n",
    "                    row_i = proximity_rows.iloc[i]\n",
    "                    row_j = proximity_rows.iloc[j]\n",
    "\n",
    "                    # Ensure numeric conversion with error handling\n",
    "                    row_i['true_proximity'] = float(row_i['true_proximity'])\n",
    "                    row_j['true_proximity'] = float(row_j['true_proximity'])\n",
    "                        \n",
    "                    # Blank out unchanged features for row_i\n",
    "                    greater_row = row_i.copy()\n",
    "                    for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                        if greater_row[column] == original_data_row[column]:\n",
    "                            greater_row[column] = \"\"  # Blank out if unchanged\n",
    "\n",
    "                    # Blank out unchanged features for row_j\n",
    "                    lesser_row = row_j.copy()\n",
    "                    for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                        if lesser_row[column] == original_data_row[column]:\n",
    "                            lesser_row[column] = \"\"  # Blank out if unchanged\n",
    "                    \n",
    "                    # See if only categorical changes were made\n",
    "                    if ((greater_row['employment_type']!=\"\" or greater_row['education_type']!=\"\") and\n",
    "                        (greater_row['income']==\"\" and greater_row['credit_score']==\"\" and greater_row['amount_requested']==\"\") and\n",
    "                        (lesser_row['employment_type']==\"\" and lesser_row['education_type']==\"\")):\n",
    "                        i_cat_change = True\n",
    "                    else:\n",
    "                        i_cat_change = False\n",
    "\n",
    "                    if i_cat_change:\n",
    "                        group_paired_rows.append(greater_row.to_dict())\n",
    "                        group_paired_rows.append(lesser_row.to_dict())\n",
    "                        # Append a separator row for readability\n",
    "                        separator = {col: \"---\" for col in df.columns}\n",
    "                        group_paired_rows.append(separator)\n",
    "\n",
    "        # Only append the original row if there are pairs in this group\n",
    "        if group_paired_rows:\n",
    "            all_paired_rows.append(original_data_row.to_dict())\n",
    "            all_paired_rows.extend(group_paired_rows)\n",
    "\n",
    "# Output debug information if no pairs were found\n",
    "if not all_paired_rows:\n",
    "    print(\"No pairs found. Review the mismatch condition or the data structure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the paired rows to a DataFrame and output to CSV\n",
    "output_df = pd.DataFrame(all_paired_rows)\n",
    "output_df.to_csv(\"hyp3_cfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYP 4\n",
    "\n",
    "df = pd.read_csv(\"cfs_formatted.csv\")\n",
    "\n",
    "# Identify separator rows and create a group for each original data section\n",
    "separator_mask = df.apply(lambda row: all(cell == \"---\" for cell in row), axis=1)\n",
    "df['group_id'] = separator_mask.cumsum()\n",
    "\n",
    "# List to collect paired results\n",
    "all_paired_rows = []\n",
    "\n",
    "# Iterate over groups to find pairs within each\n",
    "for group_id, group_df in df.groupby('group_id'):\n",
    "    # Filter out separator rows within each group\n",
    "    group_df = group_df[~separator_mask]\n",
    "\n",
    "    # Identify rows excluding the original row for pairing\n",
    "    proximity_rows = group_df[group_df['source'].str.startswith('prox')]\n",
    "\n",
    "    # Check if there are at least two rows for pairing\n",
    "    if len(proximity_rows) > 1:\n",
    "        # Treat the first row as the 'original_data' row for context\n",
    "        original_data_row = group_df[group_df['source'] == 'original'].iloc[0]\n",
    "\n",
    "        # Temporary list to collect pairs for this group\n",
    "        group_paired_rows = []\n",
    "\n",
    "        # Iterate over all possible pairs of proximity rows\n",
    "        for i in range(len(proximity_rows)):\n",
    "            for j in range(len(proximity_rows)):\n",
    "                if i != j:  # Ensure we are comparing different rows\n",
    "                    row_i = proximity_rows.iloc[i]\n",
    "                    row_j = proximity_rows.iloc[j]\n",
    "\n",
    "                    # Ensure numeric conversion with error handling\n",
    "                    row_i['true_proximity'] = float(row_i['true_proximity'])\n",
    "                    row_j['true_proximity'] = float(row_j['true_proximity'])\n",
    "\n",
    "                    # Check if j is closer than i\n",
    "                    if (\n",
    "                        row_i['true_proximity'] > row_j['true_proximity']\n",
    "                    ):\n",
    "\n",
    "                        greater_row = row_i.copy()\n",
    "                        \n",
    "                        if (float(original_data_row['credit_score']) > float(greater_row['credit_score']) or\n",
    "                            float(original_data_row['income']) > float(greater_row['income']) or\n",
    "                            float(original_data_row['amount_requested']) < float(greater_row['amount_requested'])):\n",
    "                            i_counterint = True\n",
    "                        else:\n",
    "                            i_counterint = False\n",
    "\n",
    "                        # Blank out unchanged features for row_i\n",
    "                        for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                            if greater_row[column] == original_data_row[column]:\n",
    "                                greater_row[column] = \"\"  # Blank out if unchanged\n",
    "\n",
    "                        lesser_row = row_j.copy()\n",
    "\n",
    "                        if (float(original_data_row['credit_score']) > float(lesser_row['credit_score']) or\n",
    "                            float(original_data_row['income']) > float(lesser_row['income']) or\n",
    "                            float(original_data_row['amount_requested']) < float(lesser_row['amount_requested'])):\n",
    "                            j_counterint = True\n",
    "                        else:\n",
    "                            j_counterint = False\n",
    "                        \n",
    "                        # Blank out unchanged features for row_j\n",
    "                        for column in ['income', 'credit_score', 'amount_requested', 'employment_type', 'education_type']:\n",
    "                            if lesser_row[column] == original_data_row[column]:\n",
    "                                lesser_row[column] = \"\"  # Blank out if unchanged\n",
    "\n",
    "                        # Check if j is closer but counterintuitive\n",
    "                        if j_counterint and not i_counterint:\n",
    "                            group_paired_rows.append(greater_row.to_dict())\n",
    "                            group_paired_rows.append(lesser_row.to_dict())\n",
    "                            # Append a separator row for readability\n",
    "                            separator = {col: \"---\" for col in df.columns}\n",
    "                            group_paired_rows.append(separator)\n",
    "\n",
    "        # Only append the original row if there are pairs in this group\n",
    "        if group_paired_rows:\n",
    "            all_paired_rows.append(original_data_row.to_dict())\n",
    "            all_paired_rows.extend(group_paired_rows)\n",
    "\n",
    "# Output debug information if no pairs were found\n",
    "if not all_paired_rows:\n",
    "    print(\"No pairs found. Review the mismatch condition or the data structure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the paired rows to a DataFrame and output to CSV\n",
    "output_df = pd.DataFrame(all_paired_rows)\n",
    "output_df.to_csv(\"hyp4_cfs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
