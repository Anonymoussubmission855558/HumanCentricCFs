{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy.optimize import minimize\n",
    "# from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature        Beta     Raw Cost (-Beta)    Normalized Cost (sums to 1)\n",
      "-----------------------------------------------------------------------\n",
      "income          -0.1495            0.1495                    0.6240\n",
      "credit_score     2.3537           -2.3537                    0.0511\n",
      "loan_amount      1.7930           -1.7930                    0.0895\n",
      "employment_type  1.0686           -1.0686                    0.1846\n",
      "education        2.3576           -2.3576                    0.0509\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "actual: 12, weighted: 13\n",
      "Total: 25\n"
     ]
    }
   ],
   "source": [
    "def estimate_bt(wins, tol=1e-6, max_iter=1000, prior_strength=0.1):\n",
    "    \"\"\"\n",
    "    Estimate Bradley-Terry beta parameters using an iterative update\n",
    "    (Minorization-Maximization or fixed-point approach).\n",
    "\n",
    "    Parameters:\n",
    "      wins (np.ndarray): a KxK matrix where wins[i, j] counts how many times\n",
    "                         feature i 'won' over feature j (weighted).\n",
    "      tol (float): tolerance for convergence.\n",
    "      max_iter (int): max number of iterations for convergence.\n",
    "      prior_strength (float): strength of Gaussian(0, σ²=1/prior_strength) prior.\n",
    "                         0 ⇒ pure MLE; larger ⇒ stronger shrinkage toward 0.\n",
    "\n",
    "    Returns:\n",
    "      beta (np.ndarray): array of length K with the estimated BT parameters.\n",
    "    \"\"\"\n",
    "    K = wins.shape[0]\n",
    "    beta = np.zeros(K)  # Initialize betas at 0\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        beta_new = np.copy(beta)\n",
    "        \n",
    "        for i in range(K):\n",
    "            # Sum of all wins for feature i\n",
    "            wins_i = np.sum(wins[i, :])\n",
    "            \n",
    "            # Denominator part of the BT gradient update\n",
    "            denom = 0.0\n",
    "\n",
    "            for j in range(K):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                # total comparisons between i and j\n",
    "                n_ij = wins[i, j] + wins[j, i]\n",
    "                if n_ij > 0:\n",
    "                    # add n_ij / (exp(beta[i]) + exp(beta[j]))\n",
    "                    denom += n_ij / (np.exp(beta[i]) + np.exp(beta[j]))\n",
    "            \n",
    "            if wins_i > 0 and denom > 0:\n",
    "                mle_update = np.log(wins_i) - np.log(denom)\n",
    "                # MAP update: combine MLE with a zero‐mean Gaussian prior\n",
    "                beta_new[i] = mle_update / (1.0 + prior_strength)\n",
    "                # beta_new[i] = np.log(wins_i) - np.log(denom)\n",
    "        \n",
    "        if np.max(np.abs(beta_new - beta)) < tol:\n",
    "            beta = beta_new\n",
    "            break\n",
    "        \n",
    "        beta = beta_new\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def main():\n",
    "    # 1. Define features and index mapping\n",
    "    features = [\"income\", \"credit_score\", \"loan_amount\", \"employment_type\", \"education\"]\n",
    "    feature_to_idx = {feat: idx for idx, feat in enumerate(features)}\n",
    "    K = len(features)\n",
    "    \n",
    "    # 2. Initialize wins matrix\n",
    "    wins = np.zeros((K, K))\n",
    "    \n",
    "    # 3. Example survey data\n",
    "    # Each tuple is (preferred_recourse, not_preferred_recourse).\n",
    "    actual = 0\n",
    "    weighted = 0\n",
    "    survey_data = [\n",
    "        ([\"credit_score\", \"education\"],[\"credit_score\", \"loan_amount\", \"education\"], 0),\n",
    "        ([\"credit_score\", \"education\"],[\"loan_amount\", \"education\"], 0),\n",
    "        ([\"credit_score\", \"education\"],[\"income\", \"credit_score\", \"loan_amount\", \"education\"], 1),\n",
    "        ([\"credit_score\", \"loan_amount\", \"employment_type\"],[\"education\"], 0),\n",
    "        ([\"credit_score\", \"employment_type\"],[\"loan_amount\", \"education\"], 0),\n",
    "        ([\"credit_score\", \"loan_amount\", \"employment_type\"], [\"education\"], 1),\n",
    "        ([\"credit_score\"],[\"loan_amount\"], 1),\n",
    "        ([\"credit_score\", \"education\"],[\"loan_amount\", \"education\"], 0),\n",
    "        ([\"credit_score\"],[\"loan_amount\"], 1),\n",
    "        ([\"credit_score\"],[\"credit_score\",\"loan_amount\"], 0),\n",
    "        ([\"credit_score\", \"education\"],[\"income\", \"education\"], 0),\n",
    "        ([\"credit_score\", \"loan_amount\", \"employment_type\"],[\"credit_score\", \"education\"], 1),\n",
    "        ([\"credit_score\", \"education\"],[\"income\", \"credit_score\", \"education\"], 0),\n",
    "        ([\"income\", \"loan_amount\", \"employment_type\"], [\"loan_amount\", \"education\"], 1),\n",
    "        ([\"credit_score\"],[\"credit_score\",\"loan_amount\"], 1),\n",
    "        ([\"credit_score\", \"employment_type\"],[\"credit_score\", \"loan_amount\", \"education\"], 1),\n",
    "        ([\"credit_score\"],[\"credit_score\",\"loan_amount\"], 0),\n",
    "        ([\"credit_score\", \"education\"],[\"loan_amount\", \"education\"], 0),\n",
    "        ([\"income\", \"credit_score\", \"loan_amount\", \"employment_type\"], [\"education\"], 1),\n",
    "        ([\"credit_score\"],[\"income\", \"loan_amount\"], 0),\n",
    "        ([\"credit_score\"],[\"loan_amount\"], 1),\n",
    "        ([\"credit_score\", \"loan_amount\", \"employment_type\"], [\"credit_score\", \"education\"], 1),\n",
    "        ([\"credit_score\"],[\"income\", \"credit_score\"], 0),\n",
    "        ([\"credit_score\", \"education\"],[\"income\", \"loan_amount\", \"education\"], 0),\n",
    "        ([\"income\", \"credit_score\", \"loan_amount\", \"employment_type\"], [\"credit_score\", \"education\"], 1)\n",
    "    ]\n",
    "    \n",
    "    # 4. Convert each recourse-level preference into feature-level 'wins'\n",
    "    for recourse_1, recourse_2, pref in survey_data:\n",
    "        if pref == 0:\n",
    "            recourse_pref = recourse_1\n",
    "            recourse_not_pref = recourse_2\n",
    "            weighted += 1\n",
    "        else:\n",
    "            recourse_pref = recourse_2 \n",
    "            recourse_not_pref = recourse_1\n",
    "            actual += 1\n",
    "            \n",
    "        # Weight each 'win' by 1/(|R_pref|*|R_not_pref|), so each recourse-level\n",
    "        # preference has the same overall influence, regardless of recourse size.\n",
    "        weight = 1.0 / (len(recourse_pref) * len(recourse_not_pref))\n",
    "        \n",
    "        for feat_pref in recourse_pref:\n",
    "            for feat_not in recourse_not_pref:\n",
    "                i = feature_to_idx[feat_pref]\n",
    "                j = feature_to_idx[feat_not]\n",
    "                wins[i, j] += weight\n",
    "    \n",
    "    # 5. Estimate Bradley-Terry beta parameters\n",
    "    beta = estimate_bt(wins)\n",
    "    \n",
    "   \n",
    "    # Compute raw costs as the negative of beta\n",
    "    raw_costs = -beta\n",
    "    \n",
    "    # Normalize the costs so that they sum to 1.\n",
    "    # We exponentiate to ensure all values are positive.\n",
    "    normalized_costs = np.exp(raw_costs) / np.sum(np.exp(raw_costs))\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Feature        Beta     Raw Cost (-Beta)    Normalized Cost (sums to 1)\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    for feat, b, rc, nc in zip(features, beta, raw_costs, normalized_costs):\n",
    "        print(f\"{feat:15s} {b:7.4f} {rc:17.4f} {nc:25.4f}\")\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    print(f\"\\nactual: {actual}, weighted: {weighted}\")\n",
    "    print(f\"Total: {actual + weighted}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
